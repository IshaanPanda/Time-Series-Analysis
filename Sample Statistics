import scipy.stats as stats
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import acf
from statsmodels.graphics.tsaplots import plot_acf

#### Sample Statistics
Let's generate some random data from a normal distribution to demonstrate the calculation of sample statistics.

$X_1, X_2, \ldots, X_n \sim N(0,1)$, where you can think of $n$ as the sample size.

n = 100
x = stats.norm.rvs(size = n)

Numpy has built-in methods available for arrays for calculating mean and variance.

# sample mean
print(f'Sample mean = {x.mean()}')
print(f'Sample variance = {x.var()}')

Compare these to the mean of the corresponding distribution from which the sample is drawn, which is $0$, and the variance, which is $1$. For skewness and kurtosis, we need to use functions from scipy.stats.

print(f'Sample skewness = {stats.skew(x)}')
print(f'Sample kurtosis = {stats.kurtosis(x)}')

The skewness of the distribution is $0$. The kurtosis value displayed above is the excess kurtosis, which is $0$ for the distribution. For standard deviation (volatility), we can use a Numpy method.

print(f'Sample standard deviation = {x.std()}')

To demonstrate bivariate sample statistics, we need another random sample. Let's draw this too from a standard normal distribution.

$Y_1, Y_2, \ldots, Y_n \sim N(0,1)$

y = stats.norm.rvs(size = n)

The *cov()* function in Numpy yields a covariance matrix.

np.cov(x,y)

You can extract the covariance value from the matrix:

print(f'Sample covariance = {np.cov(x,y)[0,1]}')

For the sample correlation, we use the *corrcoef()* function from Numpy.

print(f'Sample correlation = {np.corrcoef(x,y)[0,1]}')

For calculating quantiles/percentiles, we can use the *quantile()* function from Numpy.

# A single quantile
np.quantile(x, 0.05)

# Multiple quantiles
np.quantile(x, [0.01, 0.05])

For the autocorrelation function, we use the *acf()* function from statsmodels. By default, the number of lags is calculated according to the length of the data.

acf(x)

# But you can adjust the number of lags.
acf(x, nlags = 10)

# You can also include confidence intervals by providing a significance level
acf(x, nlags = 10, alpha = 0.05)

Oftentimes it's more useful to plot the autocorrelation values. For this, we use the *plot_acf()* function from statsmodels. This also includes the 95% confidence interval.

plot_acf(x)

Not surprisingly, we don't see any large autocorrelations because the data was randomly generated. Still, notice that one or two of the autocorrelations might turn out to be significant. This is purely by chance and you shouldn't interpret it as economically meaningful.

# acf of x^2
plot_acf(x**2)

#### Variance Ratio for a Random Walk Model
Let's draw returns, $r$ from a standard normal distribution. These are going to be independent and identically distributed.

r = stats.norm.rvs(size = 1000)

The sample obviously has a variance pretty close to $1$.

r.var()

At each time $t$, we can define the 2-period return as $r_t + r_{t-1}$. The 2-period return series is then:

$r_0 + r_1, r_2 + r_3, r_4 + r_5, \ldots$

The ratio of the variance of this series to the original variance is:

np.array([r[t] + r[t-1] for t in range(1, len(r), 2)]).var() / r.var()

Checking the variance ratio for multiple period returns from 1 to 5:

for k in range(1,6):
    print(np.array([r[t-k:t+1].sum() for t in range(1, len(r), k+1)]).var() / ((k+1) * r.var()))
